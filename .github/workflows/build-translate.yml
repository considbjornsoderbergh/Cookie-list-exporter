name: Build & Translate Cookie Data

on:
  workflow_dispatch:
  push:
    branches: [ main, master ]
    paths:
      - 'excel-to-json.py'
      - 'json_translator_rewrite.py'
      - 'translation_key.json'
      - '**.xlsx'
      - '.github/workflows/build-translate.yml'
      - 'requirements.txt'

permissions:
  contents: read

concurrency:
  group: build-translate-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      # Proofreading export mode: "csv" (default) or "text"
      PROOFREAD_EXPORT_MODE: csv

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        shell: bash
        run: |
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install pandas openpyxl python-dateutil
          fi

      # Step 1: Excel -> converted_cookie_data.json
      - name: Convert Excel to converted_cookie_data.json
        shell: bash
        run: |
          python excel-to-json.py
          test -f converted_cookie_data.json || { echo "::error::converted_cookie_data.json was not created"; exit 1; }

      # Step 2: Translate JSON into all locales (pretty + minified)
      - name: Generate localized JSONs (pretty + minified)
        id: translate
        shell: bash
        run: |
          python json_translator_rewrite.py --translate_keys --force

          OUT_DIR="out"
          MIN_DIR="minified"

          if [ ! -d "$OUT_DIR" ]; then
            OUT_DIR="$(ls -d out_build-* 2>/dev/null | head -n1 || true)"
          fi
          if [ ! -d "$MIN_DIR" ]; then
            MIN_DIR="$(ls -d minified_build-* 2>/dev/null | head -n1 || true)"
          fi

          if [ -z "$OUT_DIR" ] || [ ! -d "$OUT_DIR" ]; then
            echo "::error::Pretty output directory not found."
            exit 1
          fi
          if [ -z "$MIN_DIR" ] || [ ! -d "$MIN_DIR" ]; then
            echo "::error::Minified output directory not found."
            exit 1
          fi

          echo "out_dir=$OUT_DIR" >> "$GITHUB_OUTPUT"
          echo "min_dir=$MIN_DIR" >> "$GITHUB_OUTPUT"

      # ----------------- Proofreading export from out/ only -----------------

      # CSV mode: one CSV per locale in proofread_csv/
      - name: Export translated JSONs to CSV (one per locale)
        if: ${{ eq(env.PROOFREAD_EXPORT_MODE, 'csv') }}
        shell: bash
        run: |
          set -euo pipefail
          export OUT_DIR="${{ steps.translate.outputs.out_dir }}"
          mkdir -p proofread_csv
          python - << 'PY'
import json, csv, os, sys, glob

out_dir = os.environ.get("OUT_DIR", "out")
dest = "proofread_csv"
os.makedirs(dest, exist_ok=True)

files = sorted(glob.glob(os.path.join(out_dir, "cookie_data_*.json")))
if not files:
    print("No translated JSONs found in", out_dir, file=sys.stderr)
    sys.exit(1)

for path in files:
    locale = os.path.splitext(os.path.basename(path))[0].replace("cookie_data_", "")
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # union of localized column names
    dynamic_cols = set()
    for block in data.get("notice_table", []):
        for item in block.get("cookie_list", []):
            dynamic_cols.update(item.keys())
    dynamic_cols = list(dynamic_cols)

    header = ["cookie_category", "category_description"] + dynamic_cols
    rows = []

    for block in data.get("notice_table", []):
        cat = block.get("cookie_category", "")
        desc = block.get("category_description", "")
        for item in block.get("cookie_list", []):
            row = {h: "" for h in header}
            row["cookie_category"] = cat
            row["category_description"] = desc
            for k, v in item.items():
                row[k] = v
            rows.append(row)

    csv_path = os.path.join(dest, f"{locale}.csv")
    with open(csv_path, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=header)
        writer.writeheader()
        writer.writerows(rows)
    print("Wrote", csv_path)
PY
          echo "CSV export complete."
          ls -la proofread_csv | head -n 50 || true

      - name: Upload proofreading CSVs
        if: ${{ eq(env.PROOFREAD_EXPORT_MODE, 'csv') }}
        uses: actions/upload-artifact@v4
        with:
          name: translated-csv-proofread
          path: proofread_csv/
          if-no-files-found: error

      # Text mode: single UTF-8 text file with tables
      - name: Export translated JSONs to a single text file (tables)
        if: ${{ eq(env.PROOFREAD_EXPORT_MODE, 'text') }}
        shell: bash
        run: |
          set -euo pipefail
          export OUT_DIR="${{ steps.translate.outputs.out_dir }}"
          python - << 'PY'
import json, os, sys, glob

out_dir = os.environ.get("OUT_DIR", "out")
outfile = "proofread_tables.txt"

files = sorted(glob.glob(os.path.join(out_dir, "cookie_data_*.json")))
if not files:
    print("No translated JSONs found in", out_dir, file=sys.stderr)
    sys.exit(1)

def line(): return "-" * 80 + "\n"

with open(outfile, "w", encoding="utf-8") as out:
    for path in files:
        locale = os.path.splitext(os.path.basename(path))[0].replace("cookie_data_", "")
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        out.write(f"=== {locale} ===\n")
        for block in data.get("notice_table", []):
            cat = block.get("cookie_category", "")
            desc = block.get("category_description", "")
            out.write(line())
            out.write(f"Category: {cat}\n")
            out.write(f"Description: {desc}\n")
            out.write(line())

            keys = set()
            for item in block.get("cookie_list", []):
                keys.update(item.keys())
            keys = list(keys)

            out.write(" | ".join(keys) + "\n")
            out.write("-|-".join("-" * len(k) for k in keys) + "\n")

            for item in block.get("cookie_list", []):
                out.write(" | ".join(str(item.get(k, "")) for k in keys) + "\n")
            out.write("\n")
        out.write("\n")

print(f"Wrote {outfile}")
PY
          ls -lh proofread_tables.txt

      - name: Upload proofreading text
        if: ${{ eq(env.PROOFREAD_EXPORT_MODE, 'text') }}
        uses: actions/upload-artifact@v4
        with:
          name: translated-text-proofread
          path: proofread_tables.txt
          if-no-files-found: error
